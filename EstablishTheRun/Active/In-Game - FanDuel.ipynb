{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0bd50ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import packages and create date\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import difflib\n",
    "from pulp import *\n",
    "import openpyxl\n",
    "import glob\n",
    "import time\n",
    "\n",
    "from datetime import *\n",
    "today = date.today()\n",
    "today = today.strftime(\"%m.%d.20%y\")\n",
    "today\n",
    "\n",
    "time = \"7pm_\"\n",
    "# import datetime\n",
    "# today = date.today()\n",
    "# today = today - datetime.timedelta(days=1)\n",
    "# today = today.strftime(\"%m.%d.20%y\")\n",
    "# today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7e98d60",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-ded27a2d5a1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# fd = glob.glob('*-players-list.csv')[0]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mfd_upload\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'*upload-template.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfd_upload\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m17\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m19\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m22\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m23\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m26\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m27\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"FDSalaries_\"\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mcontest\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtime\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoday\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "## FanDuel Player Pool\n",
    "\n",
    "\n",
    "\n",
    "contest = \"PlayerPool_\"\n",
    "os.chdir(r\"C:\\Users\\vchang\\Downloads\")\n",
    "\n",
    "downloads = r'C:/Users/vchang/Downloads'\n",
    "contest_data_loc = r'C:/Users/vchang/Documents/Fantasy Bball/DFS/FD_Data/PlayerPool'\n",
    "\n",
    "# fd = glob.glob('*-players-list.csv')[0]\n",
    "\n",
    "fd_upload = glob.glob('*upload-template.csv')[0]\n",
    "df = pd.read_csv(fd_upload, header=6, usecols=[13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,30])\n",
    "df.to_csv(\"FDSalaries_\"+ contest + time + str(today) + \".csv\", index=False)\n",
    "# os.rename(fd, \"FDSalaries_\"+ contest + time + str(today) + \".csv\")\n",
    "\n",
    "shutil.move(downloads + \"/\"+ \"FDSalaries_\"+ contest + time + str(today) + \".csv\",\n",
    "           contest_data_loc + \"/\"+ \"FDSalaries_\"+ contest + time + str(today) + \".csv\")\n",
    "\n",
    "os.chdir(r\"C:/Users/vchang/Documents/Fantasy Bball/DFS/FD_Data/PlayerPool\")\n",
    "fanduel_file = pd.read_csv(r\"C:/Users/vchang/Documents/Fantasy Bball/DFS/FD_Data/PlayerPool/FDSalaries_\"+ contest + time + str(today) + \".csv\")\n",
    "fanduel_file.to_excel(r\"C:/Users/vchang/Documents/Fantasy Bball/DFS/FD_Data/PlayerPool/FDSalaries_\"+ contest + time + str(today) + \".xlsx\", index=False)\n",
    "os.remove(\"FDSalaries_\"+ contest + time + str(today) + \".csv\")\n",
    "\n",
    "## Uploads\n",
    "os.chdir(r\"C:\\Users\\vchang\\Downloads\")\n",
    "\n",
    "fanduel_upload = r\"C:\\Users\\vchang\\Documents\\Fantasy Bball\\DFS\\Upload\\FanDuel\\Template\"\n",
    "\n",
    "fd_upload = glob.glob('*upload-template.csv')[0]\n",
    "os.rename(fd_upload, \"FD_Upload_\"+ contest + time + str(today) + \".csv\")\n",
    "\n",
    "shutil.move(downloads + \"/\"+ \"FD_Upload_\"+ contest + time + str(today) + \".csv\",\n",
    "           fanduel_upload + \"/\"+ \"FD_Upload_\"+ contest + time + str(today) + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e66523e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Game</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BKN@NY</td>\n",
       "      <td>2022-04-06 19:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WAS@ATL</td>\n",
       "      <td>2022-04-06 20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOS@CHI</td>\n",
       "      <td>2022-04-06 20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PHO@LAC</td>\n",
       "      <td>2022-04-06 22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OKC@UTA</td>\n",
       "      <td>2022-04-06 21:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Game                Time\n",
       "0   BKN@NY 2022-04-06 19:30:00\n",
       "2  WAS@ATL 2022-04-06 20:00:00\n",
       "3  BOS@CHI 2022-04-06 20:00:00\n",
       "4  PHO@LAC 2022-04-06 22:00:00\n",
       "5  OKC@UTA 2022-04-06 21:00:00"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_filter = pd.read_excel(downloads + '/FD_Time_04.06.xlsx')\n",
    "tf = time_filter\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "\n",
    "tf['Time'] = pd.to_datetime(tf['Time'].astype(str))\n",
    "\n",
    "tf = tf[tf.Time >= current_time]\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "384e3644",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ETR Daily\n",
    "\n",
    "# changes the working directory to your downloads folder\n",
    "os.chdir(r\"C:\\Users\\vchang\\Downloads\")\n",
    "\n",
    "downloads = r'C:/Users/vchang/Downloads'\n",
    "data_loc = r'C:/Users/vchang/Documents/Fantasy Bball/DFS/ETR_Data/FanDuel'\n",
    "daily_file = \"FD NBA Projections.csv\"\n",
    "\n",
    "shutil.move(downloads + \"/\"+ daily_file,\n",
    "           data_loc + \"/\"+ daily_file)\n",
    "\n",
    "os.chdir(data_loc)\n",
    "\n",
    "df = pd.read_csv(daily_file)\n",
    "\n",
    "df.to_excel(\"ETR_Daily_\"+ time + str(today) +\".xlsx\", index=False)\n",
    "os.remove(\"FD NBA Projections.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a21c22d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Joins the FD and ETR Files to include FD Positions \n",
    "    ## ETR does not include G/F/UTIL\n",
    "\n",
    "os.chdir(r\"C:\\Users\\vchang\\Documents\\Fantasy Bball\\DFS\\PlayerPool Analysis\")\n",
    "etr = pd.read_excel(r'C:\\Users\\vchang\\Documents\\Fantasy Bball\\DFS\\ETR_Data\\FanDuel\\ETR_Daily_' + time + str(today) + \".xlsx\")\n",
    "fd = pd.read_excel(r'C:\\Users\\vchang\\Documents\\Fantasy Bball\\DFS\\FD_Data\\PlayerPool\\FDSalaries_PlayerPool_' + time + str(today) + \".xlsx\")\n",
    "\n",
    "\n",
    "fd = pd.merge(fd, \n",
    "              tf, \n",
    "              left_on='Game', \n",
    "              right_on='Game')\n",
    "\n",
    "## TO DO - check if merge on only DKNG Roster Position Works\n",
    "df = pd.merge(etr, \n",
    "              fd[['Nickname','Position', 'Id', 'Salary']], \n",
    "              left_on='Player', \n",
    "              right_on='Nickname')\n",
    "\n",
    "\n",
    "# Add 'G' Column\n",
    "# Add 'F' Column\n",
    "df['G Position'] = np.where(df['FD Position'].str.contains(\"G\"), 'G', \"\")\n",
    "df['F Position'] = np.where(df['FD Position'].str.contains(\"F\"), 'F', \"\")\n",
    "\n",
    "df['G Position'] = df['G Position'].replace('', np.nan, regex=True)\n",
    "df['F Position'] = df['F Position'].replace('', np.nan, regex=True)\n",
    "\n",
    "# Concat the list of positions\n",
    "df['list'] = df[['FD Position', 'G Position', 'F Position']].apply(lambda x: '/'.join(x.dropna()), axis=1)\n",
    "\n",
    "# ## Update Salary to INT \n",
    "# df['FD Salary'] = df['FD Salary'].str.replace(\",\",\"\").astype(float)\n",
    "\n",
    "df['Name + ID'] = df['Id'] + \":\" + df['Player']\n",
    "\n",
    "df.to_csv(\"FD_final_PlayerPool_ETR_\"+ time + str(today) +\".csv\", index=False)\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\vchang\\Documents\\Fantasy Bball\\DFS\\PlayerPool Analysis\\FD_final_PlayerPool_ETR_'+ time + str(today) + \".csv\")\n",
    "\n",
    "\n",
    "## Unnests FD Positions into each Row (explode in Python) ##\n",
    "\n",
    "# Update Salary to INT \n",
    "# df['DK Salary'] = df['DK Salary'].str.replace(\",\",\"\").astype(float)\n",
    "\n",
    "# Update FD Position to a string\n",
    "df['FD Position'] = df['FD Position'].astype(str)\n",
    "#Delimit by '/'\n",
    "df['FD Position'] = df['FD Position'].str.split('/')\n",
    "\n",
    "# Unnest columns by FD Position\n",
    "df = df.explode('FD Position')\n",
    "\n",
    "# Create Position + ID as a lookup value\n",
    "df['Position + Id'] = df['FD Position'] + \"_\" + df['Id']\n",
    "\n",
    "df.head()\n",
    "\n",
    "df.to_csv(\"FD_final_PlayerPool_ETR_\"+ time + str(today) +\".csv\", index=False)\n",
    "# os.system(\"DKNG_final_PlayerPool_ETR_\"+ time + str(today) +\".xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243d3a48",
   "metadata": {},
   "source": [
    "# Create the Constraint Problem\n",
    "\n",
    "Goal: Maximize FD Points\n",
    "\n",
    "- Total Players = 9\n",
    "- TotalSalary <= 60000\n",
    "- TotalPosition_PG = 2\n",
    "- TotalPosition_SG = 2\n",
    "- TotalPosition_SF = 2\n",
    "- TotalPosition_PF =2 \n",
    "- TotalPosition_C =1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b79175cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74042-9739 C\n",
      "74042-20640 SG\n",
      "74042-48567 PG\n",
      "74042-110357 SF\n",
      "74042-145339 PF\n",
      "74042-14498 SG\n",
      "74042-84671 PG\n",
      "74042-80808 PF\n",
      "74042-110316 SF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vchang\\Anaconda3\\lib\\site-packages\\pulp\\pulp.py:1313: UserWarning: Spaces are not permitted in the name. Converted to '_'\n",
      "  warnings.warn(\"Spaces are not permitted in the name. Converted to '_'\")\n",
      "C:\\Users\\vchang\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PG</th>\n",
       "      <th>PG</th>\n",
       "      <th>SG</th>\n",
       "      <th>SG</th>\n",
       "      <th>PF</th>\n",
       "      <th>PF</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Name + ID</th>\n",
       "      <td>74042-48567:Cameron Payne</td>\n",
       "      <td>74042-84671:Trae Young</td>\n",
       "      <td>74042-20640:Jordan Clarkson</td>\n",
       "      <td>74042-14498:Kyrie Irving</td>\n",
       "      <td>74042-145339:Obi Toppin</td>\n",
       "      <td>74042-80808:Jayson Tatum</td>\n",
       "      <td>74042-9739:JaVale McGee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  PG                      PG  \\\n",
       "Name + ID  74042-48567:Cameron Payne  74042-84671:Trae Young   \n",
       "\n",
       "                                    SG                        SG  \\\n",
       "Name + ID  74042-20640:Jordan Clarkson  74042-14498:Kyrie Irving   \n",
       "\n",
       "                                PF                        PF  \\\n",
       "Name + ID  74042-145339:Obi Toppin  74042-80808:Jayson Tatum   \n",
       "\n",
       "                                 C  \n",
       "Name + ID  74042-9739:JaVale McGee  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## BASE Optimizer\n",
    "\n",
    "df = pd.read_csv(\"FD_final_PlayerPool_ETR_\"+ time + str(today) +\".csv\", index_col=['Id', 'FD Position'], skipinitialspace=True)\n",
    "\n",
    "legal_assignments = df.index # tuples of (name, pos)\n",
    "name_set = df.index.unique(0) # a convenience\n",
    "\n",
    "costs = df['Salary'].to_dict()\n",
    "values = df['FD Points'].to_dict()\n",
    "\n",
    "# set up LP\n",
    "draft = pulp.LpVariable.dicts('selected', legal_assignments, cat='Binary')\n",
    "\n",
    "prob = pulp.LpProblem('the draft', LpMaximize)\n",
    "\n",
    "#obj\n",
    "prob += pulp.lpSum([draft[n,p]*values[n,p] for (n,p) in legal_assignments])\n",
    "\n",
    "#salary cap\n",
    "prob += pulp.lpSum([draft[n,p]*costs[n,p] for (n, p) in legal_assignments]) <= 60000\n",
    "\n",
    "# positions\n",
    "prob += pulp.lpSum([draft[n, p] for (n, p) in legal_assignments if p == 'PG']) == 2\n",
    "prob += pulp.lpSum([draft[n, p] for (n, p) in legal_assignments if p == 'SG']) == 2\n",
    "prob += pulp.lpSum([draft[n, p] for (n, p) in legal_assignments if p == 'SF']) == 2\n",
    "prob += pulp.lpSum([draft[n, p] for (n, p) in legal_assignments if p == 'PF']) == 2\n",
    "prob += pulp.lpSum([draft[n, p] for (n, p) in legal_assignments if p == 'C']) == 1\n",
    "\n",
    "# use each player at most only once\n",
    "result = []\n",
    "for name in name_set:\n",
    "    prob += pulp.lpSum([draft[n, p] for (n, p) in legal_assignments if n == name]) <= 1\n",
    "\n",
    "prob.solve()\n",
    "\n",
    "for idx in draft:\n",
    "    if draft[idx].varValue > 0:\n",
    "        print(idx[0], idx[1])\n",
    "        \n",
    "        result.append([idx[0], idx[1]])\n",
    "        \n",
    "\n",
    "        \n",
    "### Transpose dataframe from column to row\n",
    "\n",
    "new_list = result\n",
    "df = pd.DataFrame(new_list)\n",
    "test = df[[1,0]]\n",
    "\n",
    "# Create a lookup variable for [Position + Id]\n",
    "test['lookup'] = test[1] + \"_\" + test[0]\n",
    "\n",
    "\n",
    "# Merge PuLP output on [Position + Id] to pull in Player Name\n",
    "df = pd.read_csv(\"FD_final_PlayerPool_ETR_\"+ time + str(today) +\".csv\")\n",
    "upload = pd.merge(test,\n",
    "                 df[['Player', 'Position + Id', 'Name + ID']],\n",
    "                 left_on = 'lookup',\n",
    "                 right_on = 'Position + Id')\n",
    "\n",
    "\n",
    "# Drop all columns not used in upload\n",
    "upload2 = upload.drop([0, 'lookup', 'Player', 'Position + Id'], axis = 1)\n",
    "\n",
    "\n",
    "# Transpose data output from vertical to horizontal\n",
    "upload3 = upload2.transpose()\n",
    "\n",
    "\n",
    "# Rename columns to first row (position values)\n",
    "upload4 = upload3.rename(columns=upload3.iloc[0])\n",
    "\n",
    "\n",
    "# Drop duplicate first row\n",
    "upload5 = upload4.drop([1])\n",
    "\n",
    "\n",
    "# Re-order the columns to the Spositions\n",
    "upload6 = upload5[['PG',\n",
    "                   'SG',\n",
    "                   #'SF',\n",
    "                   'PF',\n",
    "                   'C'\n",
    "                  ]]\n",
    "\n",
    "upload6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fa501b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73971-58462 C\n",
      "73971-58312 SG\n",
      "73971-145540 PG\n",
      "73971-23981 PG\n",
      "73971-40199 PF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vchang\\Anaconda3\\lib\\site-packages\\pulp\\pulp.py:1313: UserWarning: Spaces are not permitted in the name. Converted to '_'\n",
      "  warnings.warn(\"Spaces are not permitted in the name. Converted to '_'\")\n",
      "C:\\Users\\vchang\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PG</th>\n",
       "      <th>PG</th>\n",
       "      <th>SG</th>\n",
       "      <th>PF</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Name + ID</th>\n",
       "      <td>73971-145540:Vit Krejci</td>\n",
       "      <td>73971-23981:Alex Caruso</td>\n",
       "      <td>73971-58312:D'Angelo Russell</td>\n",
       "      <td>73971-40199:Giannis Antetokounmpo</td>\n",
       "      <td>73971-58462:Karl-Anthony Towns</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                PG                       PG  \\\n",
       "Name + ID  73971-145540:Vit Krejci  73971-23981:Alex Caruso   \n",
       "\n",
       "                                     SG                                 PF  \\\n",
       "Name + ID  73971-58312:D'Angelo Russell  73971-40199:Giannis Antetokounmpo   \n",
       "\n",
       "                                        C  \n",
       "Name + ID  73971-58462:Karl-Anthony Towns  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Ceiling\n",
    "\n",
    "## Optimizer\n",
    "df = pd.read_csv(r'C:\\Users\\vchang\\Documents\\Fantasy Bball\\DFS\\PlayerPool Analysis\\FD_final_PlayerPool_ETR_' + time\n",
    "                 + str(today) +\".csv\", index_col=['Id', 'FD Position'], skipinitialspace=True)\n",
    "\n",
    "legal_assignments = df.index # tuples of (name, pos)\n",
    "name_set = df.index.unique(0) # a convenience\n",
    "\n",
    "costs = df['Salary'].to_dict()\n",
    "values = df['FDCeiling'].to_dict()\n",
    "\n",
    "# set up LP\n",
    "draft = pulp.LpVariable.dicts('selected', legal_assignments, cat='Binary')\n",
    "\n",
    "prob = pulp.LpProblem('the draft', LpMaximize)\n",
    "\n",
    "#obj\n",
    "prob += pulp.lpSum([draft[n,p]*values[n,p] for (n,p) in legal_assignments])\n",
    "\n",
    "#salary cap\n",
    "prob += pulp.lpSum([draft[n,p]*costs[n,p] for (n, p) in legal_assignments]) <= 34100\n",
    "\n",
    "# positions\n",
    "prob += pulp.lpSum([draft[n, p] for (n, p) in legal_assignments if p == 'PG']) == 2\n",
    "prob += pulp.lpSum([draft[n, p] for (n, p) in legal_assignments if p == 'SG']) == 1\n",
    "prob += pulp.lpSum([draft[n, p] for (n, p) in legal_assignments if p == 'SF']) == 0\n",
    "prob += pulp.lpSum([draft[n, p] for (n, p) in legal_assignments if p == 'PF']) == 1\n",
    "prob += pulp.lpSum([draft[n, p] for (n, p) in legal_assignments if p == 'C']) == 1\n",
    "\n",
    "# use each player at most only once\n",
    "result = []\n",
    "for name in name_set:\n",
    "    prob += pulp.lpSum([draft[n, p] for (n, p) in legal_assignments if n == name]) <= 1\n",
    "\n",
    "prob.solve()\n",
    "\n",
    "for idx in draft:\n",
    "    if draft[idx].varValue > 0:\n",
    "        print(idx[0], idx[1])\n",
    "        \n",
    "        result.append([idx[0], idx[1]])\n",
    "        \n",
    "        \n",
    "# Transpose dataframe from column to row\n",
    "\n",
    "new_list = result\n",
    "df = pd.DataFrame(new_list)\n",
    "test = df[[1,0]]\n",
    "\n",
    "# Create a lookup variable for [Position + Id]\n",
    "test['lookup'] = test[1] + \"_\" + test[0]\n",
    "\n",
    "\n",
    "# Merge PuLP output on [Position + Id] to pull in Player Name\n",
    "df = pd.read_csv(r'C:\\Users\\vchang\\Documents\\Fantasy Bball\\DFS\\PlayerPool Analysis\\FD_final_PlayerPool_ETR_' + time\n",
    "                 + str(today) +\".csv\", index_col=['Id', 'FD Position'], skipinitialspace=True)\n",
    "upload = pd.merge(test,\n",
    "                 df[['Player', 'Position + Id', 'Name + ID']],\n",
    "                 left_on = 'lookup',\n",
    "                 right_on = 'Position + Id')\n",
    "\n",
    "\n",
    "# Drop all columns not used in upload\n",
    "upload2 = upload.drop([0, 'lookup', 'Player', 'Position + Id'], axis = 1)\n",
    "\n",
    "\n",
    "# Transpose data output from vertical to horizontal\n",
    "upload3 = upload2.transpose()\n",
    "\n",
    "\n",
    "# Rename columns to first row (position values)\n",
    "upload4 = upload3.rename(columns=upload3.iloc[0])\n",
    "\n",
    "\n",
    "# Drop duplicate first row\n",
    "upload5 = upload4.drop([1])\n",
    "\n",
    "\n",
    "# Re-order the columns to the Spositions\n",
    "upload6 = upload5[['PG',\n",
    "                   'SG',\n",
    "                   #'SF',\n",
    "                   'PF',\n",
    "                   'C']]\n",
    "\n",
    "\n",
    "# Save as a csv\n",
    "upload6.to_csv(\"fd_result_\" + time + str(today) + \".csv\", index=None)\n",
    "\n",
    "# os.system(\"fd_result_\" + time + str(today) + \".csv\")\n",
    "\n",
    "upload6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d18ba71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73956-58312 PG\n",
      "73956-84714 PF\n",
      "73956-110357 SG\n",
      "73956-23798 SF\n",
      "73956-157822 SF\n",
      "73956-20277 SG\n",
      "73956-157907 PG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vchang\\Anaconda3\\lib\\site-packages\\pulp\\pulp.py:1313: UserWarning: Spaces are not permitted in the name. Converted to '_'\n",
      "  warnings.warn(\"Spaces are not permitted in the name. Converted to '_'\")\n",
      "C:\\Users\\vchang\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['C'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-9fabea2e061f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     81\u001b[0m                    \u001b[1;34m'SF'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m                    \u001b[1;31m#'PF',\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m                    'C']]\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3028\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3029\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3030\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3032\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1266\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1267\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1314\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1316\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{not_found} not in index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['C'] not in index\""
     ]
    }
   ],
   "source": [
    "## BASE Optimizer\n",
    "\n",
    "df = pd.read_csv(\"FD_final_PlayerPool_ETR_\"+ time + str(today) +\".csv\", index_col=['Id', 'FD Position'], skipinitialspace=True)\n",
    "\n",
    "legal_assignments = df.index # tuples of (name, pos)\n",
    "name_set = df.index.unique(0) # a convenience\n",
    "\n",
    "costs = df['Salary'].to_dict()\n",
    "values = df['FD Points'].to_dict()\n",
    "\n",
    "# set up LP\n",
    "draft = pulp.LpVariable.dicts('selected', legal_assignments, cat='Binary')\n",
    "\n",
    "prob = pulp.LpProblem('the draft', LpMaximize)\n",
    "\n",
    "#obj\n",
    "prob += pulp.lpSum([draft[n,p]*values[n,p] for (n,p) in legal_assignments])\n",
    "\n",
    "#salary cap\n",
    "prob += pulp.lpSum([draft[n,p]*costs[n,p] for (n, p) in legal_assignments]) <= 56100\n",
    "\n",
    "# positions\n",
    "prob += pulp.lpSum([draft[n, p] for (n, p) in legal_assignments if p == 'PG']) == 2\n",
    "prob += pulp.lpSum([draft[n, p] for (n, p) in legal_assignments if p == 'SG']) == 2\n",
    "prob += pulp.lpSum([draft[n, p] for (n, p) in legal_assignments if p == 'SF']) == 2\n",
    "prob += pulp.lpSum([draft[n, p] for (n, p) in legal_assignments if p == 'PF']) == 1\n",
    "prob += pulp.lpSum([draft[n, p] for (n, p) in legal_assignments if p == 'C']) == 1\n",
    "\n",
    "# use each player at most only once\n",
    "result = []\n",
    "for name in name_set:\n",
    "    prob += pulp.lpSum([draft[n, p] for (n, p) in legal_assignments if n == name]) <= 1\n",
    "\n",
    "prob.solve()\n",
    "\n",
    "for idx in draft:\n",
    "    if draft[idx].varValue > 0:\n",
    "        print(idx[0], idx[1])\n",
    "        \n",
    "        result.append([idx[0], idx[1]])\n",
    "        \n",
    "\n",
    "        \n",
    "### Transpose dataframe from column to row\n",
    "\n",
    "new_list = result\n",
    "df = pd.DataFrame(new_list)\n",
    "test = df[[1,0]]\n",
    "\n",
    "# Create a lookup variable for [Position + Id]\n",
    "test['lookup'] = test[1] + \"_\" + test[0]\n",
    "\n",
    "\n",
    "# Merge PuLP output on [Position + Id] to pull in Player Name\n",
    "df = pd.read_csv(\"FD_final_PlayerPool_ETR_\"+ time + str(today) +\".csv\")\n",
    "upload = pd.merge(test,\n",
    "                 df[['Player', 'Position + Id', 'Name + ID']],\n",
    "                 left_on = 'lookup',\n",
    "                 right_on = 'Position + Id')\n",
    "\n",
    "\n",
    "# Drop all columns not used in upload\n",
    "upload2 = upload.drop([0, 'lookup', 'Player', 'Position + Id'], axis = 1)\n",
    "\n",
    "\n",
    "# Transpose data output from vertical to horizontal\n",
    "upload3 = upload2.transpose()\n",
    "\n",
    "\n",
    "# Rename columns to first row (position values)\n",
    "upload4 = upload3.rename(columns=upload3.iloc[0])\n",
    "\n",
    "\n",
    "# Drop duplicate first row\n",
    "upload5 = upload4.drop([1])\n",
    "\n",
    "\n",
    "# Re-order the columns to the Spositions\n",
    "upload6 = upload5[['PG',\n",
    "                   #'SG',\n",
    "                   'SF',\n",
    "                   #'PF',\n",
    "                   'C']]\n",
    "\n",
    "\n",
    "# Save as a csv\n",
    "upload6.to_csv(\"fd_result_\" + time + str(today) + \".csv\", index=None)\n",
    "\n",
    "# os.system(\"fd_result_\" + time + str(today) + \".csv\")\n",
    "\n",
    "upload6\n",
    "\n",
    "\n",
    "### Upload\n",
    "upload6 = pd.read_csv(r'C:\\Users\\vchang\\Documents\\Fantasy Bball\\DFS\\PlayerPool Analysis\\fd_result_' + time + str(today) + \".csv\")\n",
    "upload6.head()\n",
    "\n",
    "\n",
    "upload = pd.read_csv(r'C:\\Users\\vchang\\Documents\\Fantasy Bball\\DFS\\Upload\\FanDuel\\Template\\FD_Upload_PlayerPool_' + time + str(today) + \".csv\"\n",
    "                     , usecols = [0,1,2], \n",
    "                     error_bad_lines=False, engine ='python')\n",
    "upload = upload.dropna()\n",
    "upload = upload[['entry_id', 'contest_id', 'contest_name']]\n",
    "\n",
    "# Drops rows that have NaN\n",
    "upload2 = upload.dropna()\n",
    "# creates value for row counts in the upload file\n",
    "repeat_rows = len(upload.index)\n",
    "\n",
    "# duplicates lineups down rows based on number of contests (length of rows)\n",
    "# copies columns from old data frame onto new dataframe\n",
    "df3 = pd.DataFrame(np.repeat(upload6.values, repeat_rows, axis=0))\n",
    "df3.columns = upload6.columns\n",
    "\n",
    "# joins the two data frames\n",
    "os.chdir(r'C:\\Users\\vchang\\Documents\\Fantasy Bball\\DFS\\Upload\\FanDuel')\n",
    "result = pd.concat([upload2, df3], axis=1)\n",
    "\n",
    "\n",
    "test = result.rename(columns={\"PG.1\":\"PG\", \"SG.1\":\"SG\", \"SF.1\":\"SF\", \"PF.1\":\"PF\"})\n",
    "result.to_csv(\"FD_Final_Upload_Base_\"+ time + str(today) + \".csv\", index=False)\n",
    "os.system(\"FD_Final_Upload_Base_\"+ time + str(today) + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "780ff325",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([1, 0], dtype='int64')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-5c628cd55c1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[0mnew_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;31m# Create a lookup variable for [Position + Id]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3028\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3029\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3030\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3032\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1266\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1267\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1306\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1307\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1308\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1310\u001b[0m             \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Int64Index([1, 0], dtype='int64')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "## BASE Optimizer\n",
    "\n",
    "df = pd.read_csv(\"FD_final_PlayerPool_ETR_\"+ time + str(today) +\".csv\", index_col=['Id', 'FD Position'], skipinitialspace=True)\n",
    "\n",
    "legal_assignments = df.index # tuples of (name, pos)\n",
    "name_set = df.index.unique(0) # a convenience\n",
    "\n",
    "costs = df['Salary'].to_dict()\n",
    "values = df['FD Points'].to_dict()\n",
    "\n",
    "# set up LP\n",
    "draft = pulp.LpVariable.dicts('selected', legal_assignments, cat='Binary')\n",
    "\n",
    "prob = pulp.LpProblem('the draft', LpMaximize)\n",
    "\n",
    "#obj\n",
    "prob += pulp.lpSum([draft[n,p]*values[n,p] for (n,p) in legal_assignments])\n",
    "\n",
    "#salary cap\n",
    "prob += pulp.lpSum([draft[n,p]*costs[n,p] for (n, p) in legal_assignments]) <= 27300\n",
    "\n",
    "# positions\n",
    "prob += pulp.lpSum([draft[n, p] for (n, p) in legal_assignments if p == 'PG']) == 1\n",
    "prob += pulp.lpSum([draft[n, p] for (n, p) in legal_assignments if p == 'SG']) == 0\n",
    "prob += pulp.lpSum([draft[n, p] for (n, p) in legal_assignments if p == 'SF']) == 1\n",
    "prob += pulp.lpSum([draft[n, p] for (n, p) in legal_assignments if p == 'PF']) == 0\n",
    "prob += pulp.lpSum([draft[n, p] for (n, p) in legal_assignments if p == 'C']) == 1\n",
    "\n",
    "# use each player at most only once\n",
    "result = []\n",
    "for name in name_set:\n",
    "    prob += pulp.lpSum([draft[n, p] for (n, p) in legal_assignments if n == name]) <= 1\n",
    "\n",
    "prob.solve()\n",
    "\n",
    "for idx in draft:\n",
    "    if draft[idx].varValue > 0:\n",
    "        print(idx[0], idx[1])\n",
    "        \n",
    "        result.append([idx[0], idx[1]])\n",
    "        \n",
    "\n",
    "        \n",
    "### Transpose dataframe from column to row\n",
    "\n",
    "new_list = result\n",
    "df = pd.DataFrame(new_list)\n",
    "test = df[[1,0]]\n",
    "\n",
    "# Create a lookup variable for [Position + Id]\n",
    "test['lookup'] = test[1] + \"_\" + test[0]\n",
    "\n",
    "\n",
    "# Merge PuLP output on [Position + Id] to pull in Player Name\n",
    "df = pd.read_csv(\"FD_final_PlayerPool_ETR_\"+ time + str(today) +\".csv\")\n",
    "upload = pd.merge(test,\n",
    "                 df[['Player', 'Position + Id', 'Name + ID']],\n",
    "                 left_on = 'lookup',\n",
    "                 right_on = 'Position + Id')\n",
    "\n",
    "\n",
    "# Drop all columns not used in upload\n",
    "upload2 = upload.drop([0, 'lookup', 'Player', 'Position + Id'], axis = 1)\n",
    "\n",
    "\n",
    "# Transpose data output from vertical to horizontal\n",
    "upload3 = upload2.transpose()\n",
    "\n",
    "\n",
    "# Rename columns to first row (position values)\n",
    "upload4 = upload3.rename(columns=upload3.iloc[0])\n",
    "\n",
    "\n",
    "# Drop duplicate first row\n",
    "upload5 = upload4.drop([1])\n",
    "\n",
    "\n",
    "# Re-order the columns to the Spositions\n",
    "upload6 = upload5[['PG',\n",
    "                   #'SG',\n",
    "                   'SF',\n",
    "                   #'PF',\n",
    "                   'C']]\n",
    "\n",
    "upload6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "978392bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vchang\\Anaconda3\\lib\\site-packages\\pulp\\pulp.py:1313: UserWarning: Spaces are not permitted in the name. Converted to '_'\n",
      "  warnings.warn(\"Spaces are not permitted in the name. Converted to '_'\")\n",
      "C:\\Users\\vchang\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73888-14528 SF\n",
      "73888-66113 PG\n",
      "73888-9575 PG\n",
      "73888-40783 SG\n",
      "73888-49116 SF\n",
      "73888-80817 PF\n",
      "73888-157849 SG\n",
      "73888-14514 C\n",
      "73888-15860 PF\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Ceiling\n",
    "\n",
    "## Optimizer\n",
    "df = pd.read_csv(r'C:\\Users\\vchang\\Documents\\Fantasy Bball\\DFS\\PlayerPool Analysis\\FD_final_PlayerPool_ETR_' + time\n",
    "                 + str(today) +\".csv\", index_col=['Id', 'FD Position'], skipinitialspace=True)\n",
    "\n",
    "legal_assignments = df.index # tuples of (name, pos)\n",
    "name_set = df.index.unique(0) # a convenience\n",
    "\n",
    "costs = df['Salary'].to_dict()\n",
    "values = df['FDCeiling'].to_dict()\n",
    "\n",
    "# set up LP\n",
    "draft = pulp.LpVariable.dicts('selected', legal_assignments, cat='Binary')\n",
    "\n",
    "prob = pulp.LpProblem('the draft', LpMaximize)\n",
    "\n",
    "#obj\n",
    "prob += pulp.lpSum([draft[n,p]*values[n,p] for (n,p) in legal_assignments])\n",
    "\n",
    "#salary cap\n",
    "prob += pulp.lpSum([draft[n,p]*costs[n,p] for (n, p) in legal_assignments]) <= 60000\n",
    "\n",
    "# positions\n",
    "prob += pulp.lpSum([draft[n, p] for (n, p) in legal_assignments if p == 'PG']) == 2\n",
    "prob += pulp.lpSum([draft[n, p] for (n, p) in legal_assignments if p == 'SG']) == 2\n",
    "prob += pulp.lpSum([draft[n, p] for (n, p) in legal_assignments if p == 'SF']) == 2\n",
    "prob += pulp.lpSum([draft[n, p] for (n, p) in legal_assignments if p == 'PF']) == 2\n",
    "prob += pulp.lpSum([draft[n, p] for (n, p) in legal_assignments if p == 'C']) == 1\n",
    "\n",
    "# use each player at most only once\n",
    "result = []\n",
    "for name in name_set:\n",
    "    prob += pulp.lpSum([draft[n, p] for (n, p) in legal_assignments if n == name]) <= 1\n",
    "\n",
    "prob.solve()\n",
    "\n",
    "for idx in draft:\n",
    "    if draft[idx].varValue > 0:\n",
    "        print(idx[0], idx[1])\n",
    "        \n",
    "        result.append([idx[0], idx[1]])\n",
    "        \n",
    "        \n",
    "# Transpose dataframe from column to row\n",
    "\n",
    "new_list = result\n",
    "df = pd.DataFrame(new_list)\n",
    "test = df[[1,0]]\n",
    "\n",
    "# Create a lookup variable for [Position + Id]\n",
    "test['lookup'] = test[1] + \"_\" + test[0]\n",
    "\n",
    "\n",
    "# Merge PuLP output on [Position + Id] to pull in Player Name\n",
    "df = pd.read_csv(r'C:\\Users\\vchang\\Documents\\Fantasy Bball\\DFS\\PlayerPool Analysis\\FD_final_PlayerPool_ETR_' + time\n",
    "                 + str(today) +\".csv\", index_col=['Id', 'FD Position'], skipinitialspace=True)\n",
    "upload = pd.merge(test,\n",
    "                 df[['Player', 'Position + Id', 'Name + ID']],\n",
    "                 left_on = 'lookup',\n",
    "                 right_on = 'Position + Id')\n",
    "\n",
    "\n",
    "# Drop all columns not used in upload\n",
    "upload2 = upload.drop([0, 'lookup', 'Player', 'Position + Id'], axis = 1)\n",
    "\n",
    "\n",
    "# Transpose data output from vertical to horizontal\n",
    "upload3 = upload2.transpose()\n",
    "\n",
    "\n",
    "# Rename columns to first row (position values)\n",
    "upload4 = upload3.rename(columns=upload3.iloc[0])\n",
    "\n",
    "\n",
    "# Drop duplicate first row\n",
    "upload5 = upload4.drop([1])\n",
    "\n",
    "\n",
    "# Re-order the columns to the Spositions\n",
    "upload6 = upload5[['PG',\n",
    "                   'SG',\n",
    "                   'SF',\n",
    "                   'PF',\n",
    "                   'C']]\n",
    "\n",
    "\n",
    "# Save as a csv\n",
    "upload6.to_csv(\"fd_result_\" + time + str(today) + \".csv\", index=None)\n",
    "\n",
    "# os.system(\"fd_result_\" + time + str(today) + \".csv\")\n",
    "\n",
    "upload6\n",
    "\n",
    "upload6 = pd.read_csv(r'C:\\Users\\vchang\\Documents\\Fantasy Bball\\DFS\\PlayerPool Analysis\\fd_result_' + time + str(today) + \".csv\")\n",
    "upload6.head()\n",
    "\n",
    "\n",
    "upload = pd.read_csv(r'C:\\Users\\vchang\\Documents\\Fantasy Bball\\DFS\\Upload\\FanDuel\\Template\\FD_Upload_PlayerPool_' + time + str(today) + \".csv\"\n",
    "                     , usecols = [0,1,2], \n",
    "                     error_bad_lines=False, engine ='python')\n",
    "upload = upload.dropna()\n",
    "upload = upload[['entry_id', 'contest_id', 'contest_name']]\n",
    "\n",
    "# Drops rows that have NaN\n",
    "upload2 = upload.dropna()\n",
    "# creates value for row counts in the upload file\n",
    "repeat_rows = len(upload2.index)\n",
    "\n",
    "# duplicates lineups down rows based on number of contests (length of rows)\n",
    "# copies columns from old data frame onto new dataframe\n",
    "df3 = pd.DataFrame(np.repeat(upload6.values, repeat_rows, axis=0))\n",
    "df3.columns = upload6.columns\n",
    "\n",
    "# joins the two data frames\n",
    "os.chdir(r'C:\\Users\\vchang\\Documents\\Fantasy Bball\\DFS\\Upload\\FanDuel')\n",
    "result = pd.concat([upload2, df3], axis=1)\n",
    "\n",
    "\n",
    "test = result.rename(columns={\"PG.1\":\"PG\", \"SG.1\":\"SG\", \"SF.1\":\"SF\", \"PF.1\":\"PF\"})\n",
    "result.to_csv(\"FD_Final_Upload_Ceiling_\"+ time + str(today) + \".csv\", index=False)\n",
    "os.system(\"FD_Final_Upload_Ceiling_\"+ time + str(today) + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6703b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672d45f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
