{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0bd50ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import packages and create date\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import difflib\n",
    "from pulp import *\n",
    "import openpyxl\n",
    "import glob\n",
    "\n",
    "from datetime import *\n",
    "today = date.today()\n",
    "today = today.strftime(\"%m.%d.20%y\")\n",
    "today\n",
    "\n",
    "time = \"1230pm_\"\n",
    "# import datetime\n",
    "# today = date.today()\n",
    "# today = today - datetime.timedelta(days=1)\n",
    "# today = today.strftime(\"%m.%d.20%y\")\n",
    "# today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7e98d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\vchang\\\\Documents\\\\Fantasy Bball\\\\DFS\\\\Upload\\\\FanDuel\\\\Template/FD_Upload_PlayerPool_9pm_04.01.2022.csv'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## FanDuel Player Pool\n",
    "\n",
    "\n",
    "\n",
    "contest = \"PlayerPool_\"\n",
    "os.chdir(r\"C:\\Users\\vchang\\Downloads\")\n",
    "\n",
    "downloads = r'C:/Users/vchang/Downloads'\n",
    "contest_data_loc = r'C:/Users/vchang/Documents/Fantasy Bball/DFS/FD_Data/PlayerPool'\n",
    "\n",
    "# fd = glob.glob('*-players-list.csv')[0]\n",
    "\n",
    "fd_upload = glob.glob('*upload-template.csv')[0]\n",
    "df = pd.read_csv(fd_upload, header=6, usecols=[13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,30])\n",
    "df.to_csv(\"FDSalaries_\"+ contest + time + str(today) + \".csv\", index=False)\n",
    "# os.rename(fd, \"FDSalaries_\"+ contest + time + str(today) + \".csv\")\n",
    "\n",
    "shutil.move(downloads + \"/\"+ \"FDSalaries_\"+ contest + time + str(today) + \".csv\",\n",
    "           contest_data_loc + \"/\"+ \"FDSalaries_\"+ contest + time + str(today) + \".csv\")\n",
    "\n",
    "os.chdir(r\"C:/Users/vchang/Documents/Fantasy Bball/DFS/FD_Data/PlayerPool\")\n",
    "fanduel_file = pd.read_csv(r\"C:/Users/vchang/Documents/Fantasy Bball/DFS/FD_Data/PlayerPool/FDSalaries_\"+ contest + time + str(today) + \".csv\")\n",
    "fanduel_file.to_excel(r\"C:/Users/vchang/Documents/Fantasy Bball/DFS/FD_Data/PlayerPool/FDSalaries_\"+ contest + time + str(today) + \".xlsx\", index=False)\n",
    "os.remove(\"FDSalaries_\"+ contest + time + str(today) + \".csv\")\n",
    "\n",
    "## Uploads\n",
    "os.chdir(r\"C:\\Users\\vchang\\Downloads\")\n",
    "\n",
    "fanduel_upload = r\"C:\\Users\\vchang\\Documents\\Fantasy Bball\\DFS\\Upload\\FanDuel\\Template\"\n",
    "\n",
    "fd_upload = glob.glob('*upload-template.csv')[0]\n",
    "os.rename(fd_upload, \"FD_Upload_\"+ contest + time + str(today) + \".csv\")\n",
    "\n",
    "shutil.move(downloads + \"/\"+ \"FD_Upload_\"+ contest + time + str(today) + \".csv\",\n",
    "           fanduel_upload + \"/\"+ \"FD_Upload_\"+ contest + time + str(today) + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "384e3644",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ETR Daily\n",
    "\n",
    "# changes the working directory to your downloads folder\n",
    "os.chdir(r\"C:\\Users\\vchang\\Downloads\")\n",
    "\n",
    "downloads = r'C:/Users/vchang/Downloads'\n",
    "data_loc = r'C:/Users/vchang/Documents/Fantasy Bball/DFS/ETR_Data/FanDuel'\n",
    "daily_file = \"FD NBA Projections.csv\"\n",
    "\n",
    "shutil.move(downloads + \"/\"+ daily_file,\n",
    "           data_loc + \"/\"+ daily_file)\n",
    "\n",
    "os.chdir(data_loc)\n",
    "\n",
    "df = pd.read_csv(daily_file)\n",
    "\n",
    "df.to_excel(\"ETR_Daily_\"+ time + str(today) +\".xlsx\", index=False)\n",
    "os.remove(\"FD NBA Projections.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a21c22d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Joins the FD and ETR Files to include FD Positions \n",
    "    ## ETR does not include G/F/UTIL\n",
    "\n",
    "os.chdir(r\"C:\\Users\\vchang\\Documents\\Fantasy Bball\\DFS\\PlayerPool Analysis\")\n",
    "etr = pd.read_excel(r'C:\\Users\\vchang\\Documents\\Fantasy Bball\\DFS\\ETR_Data\\FanDuel\\ETR_Daily_' + time + str(today) + \".xlsx\")\n",
    "fd = pd.read_excel(r'C:\\Users\\vchang\\Documents\\Fantasy Bball\\DFS\\FD_Data\\PlayerPool\\FDSalaries_PlayerPool_' + time + str(today) + \".xlsx\")\n",
    "\n",
    "## TO DO - check if merge on only DKNG Roster Position Works\n",
    "df = pd.merge(etr, \n",
    "              fd[['Nickname','Position', 'Id', 'Salary']], \n",
    "              left_on='Player', \n",
    "              right_on='Nickname')\n",
    "\n",
    "\n",
    "# Add 'G' Column\n",
    "# Add 'F' Column\n",
    "df['G Position'] = np.where(df['FD Position'].str.contains(\"G\"), 'G', \"\")\n",
    "df['F Position'] = np.where(df['FD Position'].str.contains(\"F\"), 'F', \"\")\n",
    "\n",
    "df['G Position'] = df['G Position'].replace('', np.nan, regex=True)\n",
    "df['F Position'] = df['F Position'].replace('', np.nan, regex=True)\n",
    "\n",
    "# Concat the list of positions\n",
    "df['list'] = df[['FD Position', 'G Position', 'F Position']].apply(lambda x: '/'.join(x.dropna()), axis=1)\n",
    "\n",
    "# ## Update Salary to INT \n",
    "# df['FD Salary'] = df['FD Salary'].str.replace(\",\",\"\").astype(float)\n",
    "\n",
    "df['Name + ID'] = df['Id'] + \":\" + df['Player']\n",
    "\n",
    "df.to_csv(\"FD_final_PlayerPool_ETR_\"+ time + str(today) +\".csv\", index=False)\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\vchang\\Documents\\Fantasy Bball\\DFS\\PlayerPool Analysis\\FD_final_PlayerPool_ETR_'+ time + str(today) + \".csv\")\n",
    "\n",
    "\n",
    "## Unnests FD Positions into each Row (explode in Python) ##\n",
    "\n",
    "# Update Salary to INT \n",
    "# df['DK Salary'] = df['DK Salary'].str.replace(\",\",\"\").astype(float)\n",
    "\n",
    "# Update FD Position to a string\n",
    "df['FD Position'] = df['FD Position'].astype(str)\n",
    "#Delimit by '/'\n",
    "df['FD Position'] = df['FD Position'].str.split('/')\n",
    "\n",
    "# Unnest columns by FD Position\n",
    "df = df.explode('FD Position')\n",
    "\n",
    "# Create Position + ID as a lookup value\n",
    "df['Position + Id'] = df['FD Position'] + \"_\" + df['Id']\n",
    "\n",
    "df.head()\n",
    "\n",
    "df.to_csv(\"FD_final_PlayerPool_ETR_\"+ time + str(today) +\".csv\", index=False)\n",
    "# os.system(\"DKNG_final_PlayerPool_ETR_\"+ time + str(today) +\".xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243d3a48",
   "metadata": {},
   "source": [
    "# Create the Constraint Problem\n",
    "\n",
    "Goal: Maximize FD Points\n",
    "\n",
    "- Total Players = 9\n",
    "- TotalSalary <= 60000\n",
    "- TotalPosition_PG = 2\n",
    "- TotalPosition_SG = 2\n",
    "- TotalPosition_SF = 2\n",
    "- TotalPosition_PF =2 \n",
    "- TotalPosition_C =1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d18ba71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73829-55062 C\n",
      "73829-58312 SG\n",
      "73829-12474 PG\n",
      "73829-84721 PF\n",
      "73829-17333 SF\n",
      "73829-145321 SG\n",
      "73829-9488 SF\n",
      "73829-41594 PF\n",
      "73829-40396 PG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vchang\\Anaconda3\\lib\\site-packages\\pulp\\pulp.py:1313: UserWarning: Spaces are not permitted in the name. Converted to '_'\n",
      "  warnings.warn(\"Spaces are not permitted in the name. Converted to '_'\")\n"
     ]
    }
   ],
   "source": [
    "## Optimizer\n",
    "\n",
    "df = pd.read_csv(\"FD_final_PlayerPool_ETR_\"+ time + str(today) +\".csv\", index_col=['Id', 'FD Position'], skipinitialspace=True)\n",
    "\n",
    "legal_assignments = df.index # tuples of (name, pos)\n",
    "name_set = df.index.unique(0) # a convenience\n",
    "\n",
    "costs = df['Salary'].to_dict()\n",
    "values = df['FD Points'].to_dict()\n",
    "\n",
    "# set up LP\n",
    "draft = pulp.LpVariable.dicts('selected', legal_assignments, cat='Binary')\n",
    "\n",
    "prob = pulp.LpProblem('the draft', LpMaximize)\n",
    "\n",
    "#obj\n",
    "prob += pulp.lpSum([draft[n,p]*values[n,p] for (n,p) in legal_assignments])\n",
    "\n",
    "#salary cap\n",
    "prob += pulp.lpSum([draft[n,p]*costs[n,p] for (n, p) in legal_assignments]) <= 60000\n",
    "\n",
    "# positions\n",
    "prob += pulp.lpSum([draft[n, p] for (n, p) in legal_assignments if p == 'PG']) == 2\n",
    "prob += pulp.lpSum([draft[n, p] for (n, p) in legal_assignments if p == 'SG']) == 2\n",
    "prob += pulp.lpSum([draft[n, p] for (n, p) in legal_assignments if p == 'SF']) == 2\n",
    "prob += pulp.lpSum([draft[n, p] for (n, p) in legal_assignments if p == 'PF']) == 2\n",
    "prob += pulp.lpSum([draft[n, p] for (n, p) in legal_assignments if p == 'C']) == 1\n",
    "\n",
    "# use each player at most only once\n",
    "result = []\n",
    "for name in name_set:\n",
    "    prob += pulp.lpSum([draft[n, p] for (n, p) in legal_assignments if n == name]) <= 1\n",
    "\n",
    "prob.solve()\n",
    "\n",
    "for idx in draft:\n",
    "    if draft[idx].varValue > 0:\n",
    "        print(idx[0], idx[1])\n",
    "        \n",
    "        result.append([idx[0], idx[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "56f791ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vchang\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PG</th>\n",
       "      <th>PG</th>\n",
       "      <th>SG</th>\n",
       "      <th>SG</th>\n",
       "      <th>SF</th>\n",
       "      <th>SF</th>\n",
       "      <th>PF</th>\n",
       "      <th>PF</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Name + ID</th>\n",
       "      <td>73829-12474:Patrick Beverley</td>\n",
       "      <td>73829-40396:Monte Morris</td>\n",
       "      <td>73829-58312:D'Angelo Russell</td>\n",
       "      <td>73829-145321:Anthony Edwards</td>\n",
       "      <td>73829-17333:Will Barton</td>\n",
       "      <td>73829-9488:LeBron James</td>\n",
       "      <td>73829-84721:Jarred Vanderbilt</td>\n",
       "      <td>73829-41594:Aaron Gordon</td>\n",
       "      <td>73829-55062:Nikola Jokic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     PG                        PG  \\\n",
       "Name + ID  73829-12474:Patrick Beverley  73829-40396:Monte Morris   \n",
       "\n",
       "                                     SG                            SG  \\\n",
       "Name + ID  73829-58312:D'Angelo Russell  73829-145321:Anthony Edwards   \n",
       "\n",
       "                                SF                       SF  \\\n",
       "Name + ID  73829-17333:Will Barton  73829-9488:LeBron James   \n",
       "\n",
       "                                      PF                        PF  \\\n",
       "Name + ID  73829-84721:Jarred Vanderbilt  73829-41594:Aaron Gordon   \n",
       "\n",
       "                                  C  \n",
       "Name + ID  73829-55062:Nikola Jokic  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transpose dataframe from column to row\n",
    "\n",
    "new_list = result\n",
    "df = pd.DataFrame(new_list)\n",
    "test = df[[1,0]]\n",
    "\n",
    "# Create a lookup variable for [Position + Id]\n",
    "test['lookup'] = test[1] + \"_\" + test[0]\n",
    "\n",
    "\n",
    "# Merge PuLP output on [Position + Id] to pull in Player Name\n",
    "df = pd.read_csv(\"FD_final_PlayerPool_ETR_\"+ time + str(today) +\".csv\")\n",
    "upload = pd.merge(test,\n",
    "                 df[['Player', 'Position + Id', 'Name + ID']],\n",
    "                 left_on = 'lookup',\n",
    "                 right_on = 'Position + Id')\n",
    "\n",
    "\n",
    "# Drop all columns not used in upload\n",
    "upload2 = upload.drop([0, 'lookup', 'Player', 'Position + Id'], axis = 1)\n",
    "\n",
    "\n",
    "# Transpose data output from vertical to horizontal\n",
    "upload3 = upload2.transpose()\n",
    "\n",
    "\n",
    "# Rename columns to first row (position values)\n",
    "upload4 = upload3.rename(columns=upload3.iloc[0])\n",
    "\n",
    "\n",
    "# Drop duplicate first row\n",
    "upload5 = upload4.drop([1])\n",
    "\n",
    "\n",
    "# Re-order the columns to the Spositions\n",
    "upload6 = upload5[['PG',\n",
    "                   'SG',\n",
    "                   'SF',\n",
    "                   'PF',\n",
    "                   'C']]\n",
    "\n",
    "\n",
    "# Save as a csv\n",
    "upload6.to_csv(\"fd_result_\" + time + str(today) + \".csv\", index=None)\n",
    "\n",
    "# os.system(\"fd_result_\" + time + str(today) + \".csv\")\n",
    "\n",
    "upload6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ec69a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 7: Expected 14 fields in line 7, saw 31\n",
      "Skipping line 8: Expected 14 fields in line 8, saw 31\n",
      "Skipping line 9: Expected 14 fields in line 9, saw 31\n",
      "Skipping line 10: Expected 14 fields in line 10, saw 31\n",
      "Skipping line 11: Expected 14 fields in line 11, saw 31\n",
      "Skipping line 12: Expected 14 fields in line 12, saw 31\n",
      "Skipping line 13: Expected 14 fields in line 13, saw 31\n",
      "Skipping line 14: Expected 14 fields in line 14, saw 31\n",
      "Skipping line 15: Expected 14 fields in line 15, saw 31\n",
      "Skipping line 16: Expected 14 fields in line 16, saw 31\n",
      "Skipping line 17: Expected 14 fields in line 17, saw 31\n",
      "Skipping line 18: Expected 14 fields in line 18, saw 31\n",
      "Skipping line 19: Expected 14 fields in line 19, saw 31\n",
      "Skipping line 20: Expected 14 fields in line 20, saw 31\n",
      "Skipping line 21: Expected 14 fields in line 21, saw 31\n",
      "Skipping line 22: Expected 14 fields in line 22, saw 31\n",
      "Skipping line 23: Expected 14 fields in line 23, saw 31\n",
      "Skipping line 24: Expected 14 fields in line 24, saw 31\n",
      "Skipping line 25: Expected 14 fields in line 25, saw 31\n",
      "Skipping line 26: Expected 14 fields in line 26, saw 31\n",
      "Skipping line 27: Expected 14 fields in line 27, saw 31\n",
      "Skipping line 28: Expected 14 fields in line 28, saw 31\n",
      "Skipping line 29: Expected 14 fields in line 29, saw 31\n",
      "Skipping line 30: Expected 14 fields in line 30, saw 31\n",
      "Skipping line 31: Expected 14 fields in line 31, saw 31\n",
      "Skipping line 32: Expected 14 fields in line 32, saw 31\n",
      "Skipping line 33: Expected 14 fields in line 33, saw 31\n",
      "Skipping line 34: Expected 14 fields in line 34, saw 31\n",
      "Skipping line 35: Expected 14 fields in line 35, saw 31\n",
      "Skipping line 36: Expected 14 fields in line 36, saw 31\n",
      "Skipping line 37: Expected 14 fields in line 37, saw 31\n",
      "Skipping line 38: Expected 14 fields in line 38, saw 31\n",
      "Skipping line 39: Expected 14 fields in line 39, saw 31\n",
      "Skipping line 40: Expected 14 fields in line 40, saw 31\n",
      "Skipping line 41: Expected 14 fields in line 41, saw 31\n",
      "Skipping line 42: Expected 14 fields in line 42, saw 31\n",
      "Skipping line 43: Expected 14 fields in line 43, saw 31\n",
      "Skipping line 44: Expected 14 fields in line 44, saw 31\n",
      "Skipping line 45: Expected 14 fields in line 45, saw 31\n",
      "Skipping line 46: Expected 14 fields in line 46, saw 31\n",
      "Skipping line 47: Expected 14 fields in line 47, saw 31\n",
      "Skipping line 48: Expected 14 fields in line 48, saw 31\n",
      "Skipping line 49: Expected 14 fields in line 49, saw 31\n",
      "Skipping line 50: Expected 14 fields in line 50, saw 31\n",
      "Skipping line 51: Expected 14 fields in line 51, saw 31\n",
      "Skipping line 52: Expected 14 fields in line 52, saw 31\n",
      "Skipping line 53: Expected 14 fields in line 53, saw 31\n",
      "Skipping line 54: Expected 14 fields in line 54, saw 31\n",
      "Skipping line 55: Expected 14 fields in line 55, saw 31\n",
      "Skipping line 56: Expected 14 fields in line 56, saw 31\n",
      "Skipping line 57: Expected 14 fields in line 57, saw 31\n",
      "Skipping line 58: Expected 14 fields in line 58, saw 31\n",
      "Skipping line 59: Expected 14 fields in line 59, saw 31\n",
      "Skipping line 60: Expected 14 fields in line 60, saw 31\n",
      "Skipping line 61: Expected 14 fields in line 61, saw 31\n",
      "Skipping line 62: Expected 14 fields in line 62, saw 31\n",
      "Skipping line 63: Expected 14 fields in line 63, saw 31\n",
      "Skipping line 64: Expected 14 fields in line 64, saw 31\n",
      "Skipping line 65: Expected 14 fields in line 65, saw 31\n",
      "Skipping line 66: Expected 14 fields in line 66, saw 31\n",
      "Skipping line 67: Expected 14 fields in line 67, saw 31\n",
      "Skipping line 68: Expected 14 fields in line 68, saw 31\n",
      "Skipping line 69: Expected 14 fields in line 69, saw 31\n",
      "Skipping line 70: Expected 14 fields in line 70, saw 31\n",
      "Skipping line 71: Expected 14 fields in line 71, saw 31\n",
      "Skipping line 72: Expected 14 fields in line 72, saw 31\n",
      "Skipping line 73: Expected 14 fields in line 73, saw 31\n",
      "Skipping line 74: Expected 14 fields in line 74, saw 31\n"
     ]
    }
   ],
   "source": [
    "upload6 = pd.read_csv(r'C:\\Users\\vchang\\Documents\\Fantasy Bball\\DFS\\PlayerPool Analysis\\fd_result_' + time + str(today) + \".csv\")\n",
    "upload6.head()\n",
    "\n",
    "\n",
    "upload = pd.read_csv(r'C:\\Users\\vchang\\Documents\\Fantasy Bball\\DFS\\Upload\\FanDuel\\Template\\FD_Upload_PlayerPool_' + time + str(today) + \".csv\"\n",
    "                     , #usecols = [0,1,2], \n",
    "                     error_bad_lines=False, engine ='python')\n",
    "upload = upload.dropna()\n",
    "upload = upload[['entry_id', 'contest_id', 'contest_name']]\n",
    "\n",
    "# Drops rows that have NaN\n",
    "upload2 = upload.dropna()\n",
    "# creates value for row counts in the upload file\n",
    "repeat_rows = len(upload2.index)\n",
    "\n",
    "# duplicates lineups down rows based on number of contests (length of rows)\n",
    "# copies columns from old data frame onto new dataframe\n",
    "df3 = pd.DataFrame(np.repeat(upload6.values, repeat_rows, axis=0))\n",
    "df3.columns = upload6.columns\n",
    "\n",
    "# joins the two data frames\n",
    "os.chdir(r'C:\\Users\\vchang\\Documents\\Fantasy Bball\\DFS\\Upload\\FanDuel')\n",
    "result = pd.concat([upload2, df3], axis=1)\n",
    "\n",
    "\n",
    "test = result.rename(columns={\"PG.1\":\"PG\", \"SG.1\":\"SG\", \"SF.1\":\"SF\", \"PF.1\":\"PF\"})\n",
    "result.to_csv(\"FD_Final_Upload_Base_\"+ time + str(today) + \".csv\", index=False)\n",
    "os.system(\"FD_Final_Upload_Base_\"+ time + str(today) + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978392bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6703b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85475ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
